{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image as img\n",
    "from IPython.display import display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dass_det.models.yolox import YOLOX\n",
    "from dass_det.models.yolo_head import YOLOXHead\n",
    "from dass_det.models.yolo_head_stem import YOLOXHeadStem\n",
    "from dass_det.models.yolo_pafpn import YOLOPAFPN\n",
    "\n",
    "from dass_det.data.data_augment import ValTransform\n",
    "from dass_det.data.datasets.manga109 import Manga109Dataset\n",
    "from dass_det.data.datasets.icartoonface import ICartoonFaceDataset\n",
    "from dass_det.data.datasets.comic2k import Comic2kDataset\n",
    "from dass_det.data.datasets.ebdtheque import EBDthequeDataset\n",
    "from dass_det.data.datasets.dcm772 import DCM772Dataset\n",
    "\n",
    "from dass_det.evaluators.comic_evaluator import ComicEvaluator\n",
    "\n",
    "from dass_det.utils import (\n",
    "    postprocess,\n",
    "    xyxy2xywh,\n",
    "    vis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Parameters Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"weights/sample_model.pth\" # None # \"weights/...\"\n",
    "model_size = \"xs\" # \"xl\"\n",
    "model_mode = 0    # 1 for only face, 2 for only body\n",
    "\n",
    "nms_thold  = 0.65\n",
    "conf_thold = 0.01\n",
    "\n",
    "data_paths = {\n",
    "    \"icf\"        : \"/datasets/iCartoonFace2020/\",\n",
    "    \"icf_detval\" : \"/userfiles/comics_grp/datasets/icf_val_annot/personai_icartoonface_detval.csv\",\n",
    "    \"m109\"       : \"/datasets/manga109/\",\n",
    "    \"dcm\"        : \"/userfiles/comics_grp/datasets/dcm772/dcm-dataset_from_rigaud/\",\n",
    "    \"c2k\"        : \"/userfiles/comics_grp/datasets/comic2k\",\n",
    "    \"w2k\"        : \"/userfiles/comics_grp/datasets/watercolor2k\",\n",
    "    \"c1k\"        : \"/userfiles/comics_grp/datasets/clipart2k\",\n",
    "    \"ebd\"        : \"/userfiles/comics_grp/datasets/eBDtheque2019/eBDtheque_database_v3/\",\n",
    "}\n",
    "\n",
    "data_bs = {\n",
    "    \"icf\"       : 32,\n",
    "    \"m109\"      : 24,\n",
    "    \"dcm\"       : 12,\n",
    "    \"c2k\"       : 32,\n",
    "    \"ebd\"       : 4,\n",
    "}\n",
    "\n",
    "data_imgsize = {\n",
    "    \"icf\"       : (640, 640),\n",
    "    \"m109\"      : (1152, 1632),\n",
    "    \"dcm\"       : (1600, 1600),\n",
    "    \"c2k\"       : (640, 640),\n",
    "    \"ebd\"       : (2048, 2048),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_path is not None\n",
    "assert model_size in [\"xs\", \"xl\"]\n",
    "assert model_mode in [0, 1, 2]\n",
    "\n",
    "if model_size == \"xs\":\n",
    "    depth, width = 0.33, 0.375\n",
    "elif model_size == \"xl\":\n",
    "    depth, width = 1.33, 1.25\n",
    "\n",
    "model = YOLOX(backbone=YOLOPAFPN(depth=depth, width=width),\n",
    "              head_stem=YOLOXHeadStem(width=width),\n",
    "              face_head=YOLOXHead(1, width=width),\n",
    "              body_head=YOLOXHead(1, width=width))\n",
    "\n",
    "d = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "if \"teacher_model\" in d.keys():\n",
    "    model.load_state_dict(d[\"teacher_model\"])\n",
    "else:\n",
    "    model.load_state_dict(d[\"model\"])\n",
    "model = model.eval().cuda()\n",
    "\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ICartoonFace Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ICartoonFaceDataset(data_dir={\n",
    "    \"icf_train_imgs\": os.path.join(data_paths[\"icf\"], \"personai_icartoonface_dettrain/icartoonface_dettrain/\"),\n",
    "    \"icf_test_imgs\": os.path.join(data_paths[\"icf\"], \"personai_icartoonface_detval/\"),\n",
    "    \"icf_train_labels\": os.path.join(data_paths[\"icf\"], \"personai_icartoonface_dettrain/icartoonface_dettrain.csv\"),\n",
    "    \"icf_test_labels\": data_paths[\"icf_detval\"],\n",
    "}, train=False, img_size=data_imgsize[\"icf\"], preproc=ValTransform())\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"icf\"])\n",
    "dl_iter = iter(dataloader)\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"icf\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=False, mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Manga109 Pages\n",
    "\n",
    "#### Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Manga109Dataset(data_dir=data_paths[\"m109\"],\n",
    "                          preproc=ValTransform(),\n",
    "                          train=False, img_size=data_imgsize[\"m109\"])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"m109\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"m109\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=True, select_index=1, mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Manga109Dataset(data_dir=data_paths[\"m109\"],\n",
    "                          preproc=ValTransform(),\n",
    "                          train=False, img_size=data_imgsize[\"m109\"])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"m109\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"m109\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=True, select_index=2, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate DCM772"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DCM772Dataset(data_dir=data_paths[\"dcm\"], \n",
    "                        preproc=ValTransform(),\n",
    "                        train=False, img_size=data_imgsize[\"dcm\"])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"dcm\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"dcm\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=False, select_index=1, mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bodies with Background & Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DCM772Dataset(data_dir=data_paths[\"dcm\"], \n",
    "                        preproc=ValTransform(),\n",
    "                        train=False, img_size=data_imgsize[\"dcm\"])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"dcm\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"dcm\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=False, select_index=2, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Comic2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Comic2kDataset(data_dir={\n",
    "    \"comic\": data_paths[\"c2k\"], \n",
    "    \"watercolor\": data_paths[\"w2k\"], \n",
    "    \"clipart\": data_paths[\"c1k\"]\n",
    "}, train=False, img_size=data_imgsize[\"c2k\"], filter=\"comic\")\n",
    "\n",
    "transform = ValTransform()\n",
    "dataset.preproc = transform\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"c2k\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"c2k\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=True, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Watercolor2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Comic2kDataset(data_dir={\n",
    "    \"comic\": data_paths[\"c2k\"], \n",
    "    \"watercolor\": data_paths[\"w2k\"], \n",
    "    \"clipart\": data_paths[\"c1k\"]\n",
    "}, train=False, img_size=data_imgsize[\"c2k\"], filter=\"watercolor\")\n",
    "\n",
    "transform = ValTransform()\n",
    "dataset.preproc = transform\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"c2k\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"c2k\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=True, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Clipart 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Comic2kDataset(data_dir={\n",
    "    \"comic\": data_paths[\"c2k\"], \n",
    "    \"watercolor\": data_paths[\"w2k\"], \n",
    "    \"clipart\": data_paths[\"c1k\"]\n",
    "}, train=False, img_size=data_imgsize[\"c2k\"], filter=\"clipart\")\n",
    "\n",
    "transform = ValTransform()\n",
    "dataset.preproc = transform\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"c2k\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"c2k\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=True, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate eBDtheque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (2048, 2048)\n",
    "bs       = 4\n",
    "\n",
    "dataset = EBDthequeDataset(data_dir={\n",
    "    \"imgs\": os.path.join(data_paths[\"ebd\"], \"Pages/\"),\n",
    "    \"labels\": os.path.join(data_paths[\"ebd\"], \"GT/\"),\n",
    "}, train=False, img_size=data_imgsize[\"ebd\"], preproc=ValTransform())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=data_bs[\"ebd\"])\n",
    "\n",
    "evaluator = ComicEvaluator(dataloader, data_imgsize[\"ebd\"], nms_thold, conf_thold, 1, use_real_size=False, verbose=True)\n",
    "results = evaluator.evaluate(model, use_07_metric=False, mode=2, select_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICartoonFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set these paths by yourself if you want to extract prediction csv's for original iCartoonFace evaluations\n",
    "icf_path = \"/datasets/iCartoonFace2020/personai_icartoonface_detval/\"\n",
    "save_path = f'eval_outs/icf_outs/icf_yolox_preds_{conf_thold}_{nms_thold}.csv'\n",
    "\n",
    "files = os.listdir(icf_path)\n",
    "transform = ValTransform()\n",
    "\n",
    "f = open(save_path, \"w\")\n",
    "\n",
    "for file in tqdm(files):\n",
    "    imgs = cv2.imread(os.path.join(icf_path, file))\n",
    "    h, w, c = imgs.shape\n",
    "    resize_size = data_imgsize[\"icf\"]\n",
    "\n",
    "    imgs, labels = transform(imgs, None, resize_size)\n",
    "    img_cu = torch.from_numpy(imgs).unsqueeze(0).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, _ = model(img_cu, None, mode=1)\n",
    "        preds = postprocess(preds, 1, conf_thold, nms_thold)[0]\n",
    "    \n",
    "    del img_cu\n",
    "    \n",
    "    if preds is None:\n",
    "        continue\n",
    "      \n",
    "    scale = min(resize_size[0] / float(h), resize_size[1] / float(w))\n",
    "    preds[:,:4] /= scale\n",
    "    preds[:,0]  = torch.max(preds[:,0], torch.zeros(preds.shape[0]).cuda())\n",
    "    preds[:,1]  = torch.max(preds[:,1], torch.zeros(preds.shape[0]).cuda())\n",
    "    preds[:,2]  = torch.min(preds[:,2], torch.zeros(preds.shape[0]).fill_(w).cuda())\n",
    "    preds[:,3]  = torch.min(preds[:,3], torch.zeros(preds.shape[0]).fill_(h).cuda())\n",
    "    \n",
    "    for i in range(preds.shape[0]):\n",
    "        x1, y1, x2, y2, conf = preds[i,:5]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        f.write(f'{file},{x1},{y1},{x2},{y2},face,{conf}\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolox",
   "language": "python",
   "name": "yolox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
